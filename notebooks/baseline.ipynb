{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08f77b0-5511-481a-afae-87d72a4498b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ee1e67-5de1-4f16-bb4b-504c8218aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'BATCH_SIZE': 4096,\n",
    "    'EPOCHS': 10,\n",
    "    'LEARNING_RATE': 1e-3,\n",
    "    'SEED' : 42\n",
    "}\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b177c553-0b65-436a-aea7-3475e77a2bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (10704179, 119)\n",
      "Test shape: (1527298, 118)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "all_train = pd.read_parquet(\"./train.parquet\", engine=\"pyarrow\")\n",
    "test = pd.read_parquet(\"./test.parquet\", engine=\"pyarrow\").drop(columns=['ID'])\n",
    "\n",
    "print(\"Train shape:\", all_train.shape)\n",
    "print(\"Test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8025f2ce-0183-44fb-8b8b-7e20470d40e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clicked\n",
       "0    10500000\n",
       "1      204179\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train['clicked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d982c4-509a-4fed-bca1-b1360fe0e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicked == 1 데이터\n",
    "clicked_1 = all_train[all_train['clicked'] == 1]\n",
    "\n",
    "# clicked == 0 데이터에서 동일 개수x2 만큼 무작위 추출 (다운 샘플링)\n",
    "clicked_0 = all_train[all_train['clicked'] == 0].sample(n=len(clicked_1)*2, random_state=42)\n",
    "\n",
    "# 두 데이터프레임 합치기\n",
    "train = pd.concat([clicked_1, clicked_0], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01239461-0d3b-4af5-9f2a-376893578e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 117\n",
      "Sequence: seq\n",
      "Target: clicked\n"
     ]
    }
   ],
   "source": [
    "# Target / Sequence\n",
    "target_col = \"clicked\"\n",
    "seq_col = \"seq\"\n",
    "\n",
    "# 학습에 사용할 피처: ID/seq/target 제외, 나머지 전부\n",
    "FEATURE_EXCLUDE = {target_col, seq_col, \"ID\"}\n",
    "feature_cols = [c for c in train.columns if c not in FEATURE_EXCLUDE]\n",
    "\n",
    "print(\"Num features:\", len(feature_cols))\n",
    "print(\"Sequence:\", seq_col)\n",
    "print(\"Target:\", target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696ca680-e7c8-4b6c-bf7a-bf09f4c25bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClickDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, seq_col, target_col=None, has_target=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.feature_cols = feature_cols\n",
    "        self.seq_col = seq_col\n",
    "        self.target_col = target_col\n",
    "        self.has_target = has_target\n",
    "\n",
    "        # 비-시퀀스 피처: 전부 연속값으로\n",
    "        self.X = self.df[self.feature_cols].astype(float).fillna(0).values\n",
    "\n",
    "        # 시퀀스: 문자열 그대로 보관 (lazy 파싱)\n",
    "        self.seq_strings = self.df[self.seq_col].astype(str).values\n",
    "\n",
    "        if self.has_target:\n",
    "            self.y = self.df[self.target_col].astype(np.float32).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx], dtype=torch.float)\n",
    "\n",
    "        # 전체 시퀀스 사용 (빈 시퀀스만 방어)\n",
    "        s = self.seq_strings[idx]\n",
    "        if s:\n",
    "            arr = np.fromstring(s, sep=\",\", dtype=np.float32)\n",
    "        else:\n",
    "            arr = np.array([], dtype=np.float32)\n",
    "\n",
    "        if arr.size == 0:\n",
    "            arr = np.array([0.0], dtype=np.float32)  # 빈 시퀀스 방어\n",
    "\n",
    "        seq = torch.from_numpy(arr)  # shape (seq_len,)\n",
    "\n",
    "        if self.has_target:\n",
    "            y = torch.tensor(self.y[idx], dtype=torch.float)\n",
    "            return x, seq, y\n",
    "        else:\n",
    "            return x, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "172aef87-03ce-4276-ae9f-321a84c32824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_train(batch):\n",
    "    xs, seqs, ys = zip(*batch)\n",
    "    xs = torch.stack(xs)\n",
    "    ys = torch.stack(ys)\n",
    "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
    "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    seq_lengths = torch.clamp(seq_lengths, min=1)  # 빈 시퀀스 방지\n",
    "    return xs, seqs_padded, seq_lengths, ys\n",
    "\n",
    "def collate_fn_infer(batch):\n",
    "    xs, seqs = zip(*batch)\n",
    "    xs = torch.stack(xs)\n",
    "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
    "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    seq_lengths = torch.clamp(seq_lengths, min=1)\n",
    "    return xs, seqs_padded, seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c92be06a-d9bd-4a16-b584-7815a81a5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularSeqModel(nn.Module):\n",
    "    def __init__(self, d_features, lstm_hidden=32, hidden_units=[1024, 512, 256, 128], dropout=0.2):\n",
    "        super().__init__()\n",
    "        # 모든 비-시퀀스 피처에 BN\n",
    "        self.bn_x = nn.BatchNorm1d(d_features)\n",
    "        # seq: 숫자 시퀀스 → LSTM\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=lstm_hidden, batch_first=True)\n",
    "\n",
    "        # 최종 MLP\n",
    "        input_dim = d_features + lstm_hidden\n",
    "        layers = []\n",
    "        for h in hidden_units:\n",
    "            layers += [nn.Linear(input_dim, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            input_dim = h\n",
    "        layers += [nn.Linear(input_dim, 1)]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x_feats, x_seq, seq_lengths):\n",
    "        # 비-시퀀스 피처\n",
    "        x = self.bn_x(x_feats)\n",
    "\n",
    "        # 시퀀스 → LSTM (pack)\n",
    "        x_seq = x_seq.unsqueeze(-1)  # (B, L, 1)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            x_seq, seq_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        h = h_n[-1]                  # (B, lstm_hidden)\n",
    "\n",
    "        z = torch.cat([x, h], dim=1)\n",
    "        return self.mlp(z).squeeze(1)  # logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6abd3a0a-627a-445f-9d46-51d1924d4e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df, feature_cols, seq_col, target_col,\n",
    "                batch_size=512, epochs=3, lr=1e-3, device=\"cuda\"):\n",
    "\n",
    "    # 1) split\n",
    "    tr_df, va_df = train_test_split(train_df, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # 2) Dataset / Loader (l_max 인자 제거)\n",
    "    train_dataset = ClickDataset(tr_df, feature_cols, seq_col, target_col, has_target=True)\n",
    "    val_dataset   = ClickDataset(va_df, feature_cols, seq_col, target_col, has_target=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  collate_fn=collate_fn_train)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=collate_fn_train)\n",
    "\n",
    "    # 3) 모델\n",
    "    d_features = len(feature_cols)\n",
    "    model = TabularSeqModel(d_features=d_features, lstm_hidden=64, hidden_units=[256,128], dropout=0.2).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # 4) Loop\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for xs, seqs, seq_lens, ys in tqdm(train_loader, desc=f\"Train Epoch {epoch}\"):\n",
    "            xs, seqs, seq_lens, ys = xs.to(device), seqs.to(device), seq_lens.to(device), ys.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xs, seqs, seq_lens)\n",
    "            loss = criterion(logits, ys)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * ys.size(0)\n",
    "        train_loss /= len(train_dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xs, seqs, seq_lens, ys in tqdm(val_loader, desc=f\"Val Epoch {epoch}\"):\n",
    "                xs, seqs, seq_lens, ys = xs.to(device), seqs.to(device), seq_lens.to(device), ys.to(device)\n",
    "                logits = model(xs, seqs, seq_lens)\n",
    "                loss = criterion(logits, ys)\n",
    "                val_loss += loss.item() * len(ys)\n",
    "        val_loss /= len(val_dataset)\n",
    "\n",
    "        print(f\"[Epoch {epoch}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af85737-5a9f-4edf-b1eb-aaef6d393d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|██████████████████████████████████████████████████████████████████| 120/120 [01:12<00:00,  1.65it/s]\n",
      "Val Epoch 1: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [00:14<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.5904 | Val Loss: 0.5746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 100%|██████████████████████████████████████████████████████████████████| 120/120 [01:09<00:00,  1.72it/s]\n",
      "Val Epoch 2: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [00:14<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 0.5740 | Val Loss: 0.5706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 100%|██████████████████████████████████████████████████████████████████| 120/120 [01:09<00:00,  1.73it/s]\n",
      "Val Epoch 3: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [00:14<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 0.5702 | Val Loss: 0.5706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: 100%|██████████████████████████████████████████████████████████████████| 120/120 [01:09<00:00,  1.72it/s]\n",
      "Val Epoch 4: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [00:14<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 0.5680 | Val Loss: 0.5671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: 100%|██████████████████████████████████████████████████████████████████| 120/120 [01:09<00:00,  1.72it/s]\n",
      "Val Epoch 5: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [00:14<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 0.5666 | Val Loss: 0.5664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6: 100%|██████████████████████████████████████████████████████████████████| 120/120 [00:47<00:00,  2.52it/s]\n",
      "Val Epoch 6: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [00:14<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 0.5648 | Val Loss: 0.5663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 7: 100%|██████████████████████████████████████████████████████████████████| 120/120 [01:09<00:00,  1.72it/s]\n",
      "Val Epoch 7: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [00:14<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 0.5638 | Val Loss: 0.5656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 8: 100%|██████████████████████████████████████████████████████████████████| 120/120 [01:09<00:00,  1.72it/s]\n",
      "Val Epoch 8: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [00:14<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 0.5626 | Val Loss: 0.5642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 9: 100%|██████████████████████████████████████████████████████████████████| 120/120 [01:09<00:00,  1.73it/s]\n",
      "Val Epoch 9: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [00:14<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 0.5615 | Val Loss: 0.5650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 10: 100%|█████████████████████████████████████████████████████████████████| 120/120 [01:09<00:00,  1.72it/s]\n",
      "Val Epoch 10: 100%|█████████████████████████████████████████████████████████████████████| 30/30 [00:14<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 0.5610 | Val Loss: 0.5639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_model(\n",
    "    train_df=train,\n",
    "    feature_cols=feature_cols,\n",
    "    seq_col=seq_col,\n",
    "    target_col=target_col,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    epochs=CFG['EPOCHS'],\n",
    "    lr=CFG['LEARNING_RATE'],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8685c72d-0140-49f1-99b2-2dea3d6d272b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████████████████████████████████████████████████████████████████| 373/373 [02:21<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1) Dataset/Loader\n",
    "test_ds = ClickDataset(test, feature_cols, seq_col, has_target=False)\n",
    "test_ld = DataLoader(test_ds, batch_size=CFG['BATCH_SIZE'], shuffle=False, collate_fn=collate_fn_infer)\n",
    "\n",
    "# 2) Predict\n",
    "model.eval()\n",
    "outs = []\n",
    "with torch.no_grad():\n",
    "    for xs, seqs, lens in tqdm(test_ld, desc=\"Inference\"):\n",
    "        xs, seqs, lens = xs.to(device), seqs.to(device), lens.to(device)\n",
    "        outs.append(torch.sigmoid(model(xs, seqs, lens)).cpu())\n",
    "\n",
    "test_preds = torch.cat(outs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a090d39-c5b2-4195-81aa-728ebdb1d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['clicked'] = test_preds\n",
    "submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "346e904d-e9ee-4eef-9fcc-ea1f8c399a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age_group</th>\n",
       "      <th>inventory_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>seq</th>\n",
       "      <th>l_feat_1</th>\n",
       "      <th>l_feat_2</th>\n",
       "      <th>l_feat_3</th>\n",
       "      <th>l_feat_4</th>\n",
       "      <th>...</th>\n",
       "      <th>history_b_22</th>\n",
       "      <th>history_b_23</th>\n",
       "      <th>history_b_24</th>\n",
       "      <th>history_b_25</th>\n",
       "      <th>history_b_26</th>\n",
       "      <th>history_b_27</th>\n",
       "      <th>history_b_28</th>\n",
       "      <th>history_b_29</th>\n",
       "      <th>history_b_30</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>321,516,57,74,527,77,317,75,269,450,15,75,483,...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115092</td>\n",
       "      <td>0.115092</td>\n",
       "      <td>0.019182</td>\n",
       "      <td>0.007673</td>\n",
       "      <td>0.071613</td>\n",
       "      <td>0.081843</td>\n",
       "      <td>0.025576</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.126598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>07</td>\n",
       "      <td>144,57,516,97,165,527,74,318,77,317,480,480,28...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125694</td>\n",
       "      <td>0.125694</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>0.078210</td>\n",
       "      <td>0.089382</td>\n",
       "      <td>0.027932</td>\n",
       "      <td>0.072623</td>\n",
       "      <td>0.184358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>08</td>\n",
       "      <td>516,57,408,408,408,408,154,408,269,479,57,408,...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075060</td>\n",
       "      <td>0.075060</td>\n",
       "      <td>0.012510</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.046704</td>\n",
       "      <td>0.053376</td>\n",
       "      <td>0.016680</td>\n",
       "      <td>0.043368</td>\n",
       "      <td>0.110091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>00</td>\n",
       "      <td>9,57,516,338,416,516,114,195,27,516,527,74,318...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060318</td>\n",
       "      <td>0.060318</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.037531</td>\n",
       "      <td>0.042893</td>\n",
       "      <td>0.013404</td>\n",
       "      <td>0.034850</td>\n",
       "      <td>0.022117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>138,132,9,101,532,74,77,318,132,101,532,101,13...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066816</td>\n",
       "      <td>0.066816</td>\n",
       "      <td>0.011136</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>0.047514</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>0.038605</td>\n",
       "      <td>0.048998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612532</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>9,18,516,57,97,74,527,318,77,463,212,193,151,1...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028881</td>\n",
       "      <td>0.028881</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.107828</td>\n",
       "      <td>0.041075</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.033374</td>\n",
       "      <td>0.328307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612533</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>57,516,74,452,318,207,269,452,245,508,51,508,5...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.101587</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.082540</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612534</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>9,57,516,97,74,527,77,132,532,138,101,101,132,...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030708</td>\n",
       "      <td>0.030708</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.013648</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.067554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612535</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>57,516,97,527,74,315,317,269,311,479,57,74,315...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103689</td>\n",
       "      <td>0.103689</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>0.006913</td>\n",
       "      <td>0.064518</td>\n",
       "      <td>0.073734</td>\n",
       "      <td>0.023042</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>0.114055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612536</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>9,57,516,527,74,77,532,132,138,101,101,101,532...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062199</td>\n",
       "      <td>0.062199</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.038702</td>\n",
       "      <td>0.044230</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.022806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>612537 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender age_group inventory_id day_of_week hour  \\\n",
       "0         2.0       7.0            2           1   22   \n",
       "1         1.0       7.0            2           3   07   \n",
       "2         2.0       7.0            2           6   08   \n",
       "3         1.0       7.0            2           3   00   \n",
       "4         1.0       7.0           37           6   22   \n",
       "...       ...       ...          ...         ...  ...   \n",
       "612532    1.0       7.0           36           5   20   \n",
       "612533    1.0       8.0           37           2   10   \n",
       "612534    2.0       8.0            2           1   01   \n",
       "612535    1.0       8.0            2           1   13   \n",
       "612536    2.0       6.0           43           2   22   \n",
       "\n",
       "                                                      seq  l_feat_1  l_feat_2  \\\n",
       "0       321,516,57,74,527,77,317,75,269,450,15,75,483,...       2.0       2.0   \n",
       "1       144,57,516,97,165,527,74,318,77,317,480,480,28...       2.0       2.0   \n",
       "2       516,57,408,408,408,408,154,408,269,479,57,408,...       2.0       2.0   \n",
       "3       9,57,516,338,416,516,114,195,27,516,527,74,318...       2.0       2.0   \n",
       "4       138,132,9,101,532,74,77,318,132,101,532,101,13...       2.0       2.0   \n",
       "...                                                   ...       ...       ...   \n",
       "612532  9,18,516,57,97,74,527,318,77,463,212,193,151,1...       1.0       2.0   \n",
       "612533  57,516,74,452,318,207,269,452,245,508,51,508,5...       2.0       2.0   \n",
       "612534  9,57,516,97,74,527,77,132,532,138,101,101,132,...       2.0       2.0   \n",
       "612535  57,516,97,527,74,315,317,269,311,479,57,74,315...       2.0       2.0   \n",
       "612536  9,57,516,527,74,77,532,132,138,101,101,101,532...       2.0       2.0   \n",
       "\n",
       "        l_feat_3  l_feat_4  ...  history_b_22  history_b_23  history_b_24  \\\n",
       "0            2.0      22.0  ...      0.115092      0.115092      0.019182   \n",
       "1            2.0      24.0  ...      0.125694      0.125694      0.020949   \n",
       "2            2.0       7.0  ...      0.075060      0.075060      0.012510   \n",
       "3            2.0       8.0  ...      0.060318      0.060318      0.010053   \n",
       "4            2.0       7.0  ...      0.066816      0.066816      0.011136   \n",
       "...          ...       ...  ...           ...           ...           ...   \n",
       "612532       1.0       7.0  ...      0.028881      0.028881      0.004814   \n",
       "612533       2.0      22.0  ...      0.142857      0.142857      0.023810   \n",
       "612534       3.0      16.0  ...      0.030708      0.030708      0.005118   \n",
       "612535       2.0       7.0  ...      0.103689      0.103689      0.017282   \n",
       "612536       2.0      14.0  ...      0.062199      0.062199      0.010367   \n",
       "\n",
       "        history_b_25  history_b_26  history_b_27  history_b_28  history_b_29  \\\n",
       "0           0.007673      0.071613      0.081843      0.025576      0.066498   \n",
       "1           0.008380      0.078210      0.089382      0.027932      0.072623   \n",
       "2           0.005004      0.046704      0.053376      0.016680      0.043368   \n",
       "3           0.004021      0.037531      0.042893      0.013404      0.034850   \n",
       "4           0.004454      0.041574      0.047514      0.014848      0.038605   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "612532      0.001925      0.107828      0.041075      0.006418      0.033374   \n",
       "612533      0.009524      0.088889      0.101587      0.031746      0.082540   \n",
       "612534      0.002047      0.019107      0.021837      0.013648      0.017742   \n",
       "612535      0.006913      0.064518      0.073734      0.023042      0.059909   \n",
       "612536      0.004147      0.038702      0.044230      0.013822      0.035937   \n",
       "\n",
       "        history_b_30  clicked  \n",
       "0           0.126598        0  \n",
       "1           0.184358        0  \n",
       "2           0.110091        1  \n",
       "3           0.022117        0  \n",
       "4           0.048998        0  \n",
       "...              ...      ...  \n",
       "612532      0.328307        1  \n",
       "612533      0.052381        0  \n",
       "612534      0.067554        0  \n",
       "612535      0.114055        1  \n",
       "612536      0.022806        1  \n",
       "\n",
       "[612537 rows x 119 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ljh_312",
   "language": "python",
   "name": "ljh_312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
